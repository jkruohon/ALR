﻿﻿4 läksyä jotka ARVOSTELLAAN ja muodostavat 2/3 arvosanasta.

!!läksyjen on oltava pdf-muodossa!!

loppukoe u35 s113 3.5. muodostaa 1/3 arvosanasta.

jos yhteispisteet väh. 50% kaikista niin läpi menee.  eli saamalla täydet pisteet kotiläksyistä pääsee läpi helposti.

perusregressiossa ordinary least squares (OLF).  logistisessa Likelihood Function.   ja Maximum Likelihood Estimation. 


... tarkoittaa "jotenka"
e kaavassa tarkoittaa expected.


poisson ja cox ennustavat 0-1 välillä liikkuvaa vastetta. ne ovat myös yleistettyjä lineaarisia malleja.

LR:ssä ei selittäjien jakaumasta ole mitään olettamuksia (toisin kuin LDA:ssa ja joissain muissa)

esim:  vaste Y, selittäjä A, kolmas muuttuja K.

yleensä jos epäilleen confounderia niin se vakioidaan. (tosin regressiossahan tämä tapahtuu automaattisesti). tai sitten käytetään verrokkiryhmää.   jos K:n arvoa ei tiedetä tutkimusryhmässä niin verrokkiryhmässä se randomoidaan (jos ei voida vakioida).

Main types of observational causal research:

1.kohorttitutkimus. kohortti on ryhmä ihmisiä joista kaikki ovat altistuneet tekijälle X samaan aikaan.

birth cohort people who were born in the same year.
student cohort freshmen sophomores seniors etc.

principle: follow the cohort, record exposures (?) and subsequent responses.


case-control study:
principle: select cases (of a particular illness), and for those controls who didnt become ill. then you find out about earlier exposures.

bernoulli muuttuja on binäärinen.   

E[y] = p*1  öööööööööö

E[y^2] = p*1

varianssi: p * 1-p.

E[y1+y2] = E[y1] + E[y1]
this same is not true for variance.
var(y1+y2) = var(y1)+var(y2) vain jos y1 ja y2 ovat toisistaan riippuamttomia.

covariance: y1*y2 = ohi

Maximum Likelihood Estimation(MLI):
likelihood function: ei pysty kirjottaa näppiksel.  likelihood is the probability of the observed data.  likelihood function mittaa sen. what value of P maximizes the Maximum Likelihood?    log likelihood is the logarithm of the maximum likelihood. 

biased vs unbiased MLE? vaikuttaa tärkeältä.

MLE:n varianssi on sama kaava kuin suhteellisen osuuden keskivirhe!

SdErr = SD of p-hat.   estimaattorin (=estimaatin? otoksen?) keskihajontaa sanotaan keskivirheeksi jostain syystä.


Z-value on siis observed - expected / keskivirhe. Z on tietysti normaalijakautunut. keskiarvo 0 ja hajonta 1. siksi se on niin kiva.

20-30 kuulemma hyvä N.

nyt täällä näytetään p:n luottamusvälin laskeminen. näytää olevan tasan sama kaava kuin suhteellisen osuuden luottamusvälin laskeminen. 

"these are the best models for these kinds of data."

when using a model, always think about whether its assumptions are true.

esim tautiEPIDEMIAN tapauksessa havainnot ei pakosti oo riippumattomia.

nykyään käytetään hypoteesin testauksen sijasta luottamusvälejä.

CI for p1-p0: huh jospa otamme kuvan.

2x2 table (contingency) hän selittää vapausasteet. jos reunajakaumat ovat vakiot niin vain yksi voi solu voi vaihdella. muiden arvot riippuvat suoraan siitä.

uurnamallissa otos tehdään PALAUTTAMATTA. ei ole buutsträppiä tämä.

z toiseen on kuulemma sama kuin chi-squaren arvo vapausasteilla 1.

muntel&henzel testissä h0 on että kaikken solujen oddsratiot ovat samat. sitten arvioidaan.

cochran muntel henzel test. X^2

tilastotieteessä ei kuulemma käytetä muita logaritmeja kuin luonnollisia logaritmeja. kaikki logaritmit oletettavasti ovat neperin luvun logaritmeja.

options(digits=2) käskee R:ää OLETUSARVOISESTI käyttämään vain kahta desimaalia laskutoimituksissa.

element-wise operations!!!

perus-R:n plotilla type="l"  piirtää VIIVAN!!!

näissä binomiaalijutuissa 3.84 on se tärkeä arvo.  se on 1.96^2.  ja se on kuulemma se tärkeä.

raja-arvolause: phat lähestyy ... ohi. Paha kirjottaa tota näppiksellä. 

p-arvon luottamusväli from phat - 1.96SE to phat+1.96SE

mantzel henzel on kolmiluotteisen ristitaulukon chisquare testi ikäänkuin.  siellä on selitettävä, selittäjä ja confounder. jotenkin se sitten testaa nollahypoteesia että.... että oddsratio on sama selittäjissä, oli confounder läsnä tai ei.  tai että oddsratio on sama confounder läsnä -ryhmässä ja confounderia ei-ryhmässä. Jotenkin tosi fiksulta se vaikutti mutta täysin selville en päässyt. 

Cochran-Mandel-Haenzel testi taitaa siis testata sitä nollahypoteesia, että x:n selitysvoima y:hyn (odds ratio) on sama kahdessa (tai useammassa) eri potentiaalisen sekoittavan muuttujan K luokassa. jos p-arvoksi tulee <0.05, niin voidaan 95% varmuudella todeta, että sekoittajan luokilla on vaikutusta odds ratioon eli se confoundaa. Kuitenkin tulokset vaihtelevat sen perusteella, käytetäänkö Yatesin jatkuvuuskorjausta (correct = TRUE)

logit-funktio. logit(p)  p (0,1)
logit (p/1-p) siis. eli logit(odds).  eli log-odds.

LR sanoo:  logit(Pi) = B0 + B1Xi, ... B2Xi. i ilmeisesti AINA tarkoittaa tiettyä havaintoyksikköä/yksilöä.

theta on yhtä kuin logodds tässä notaatiossa.  vai onko se log(p)???

logit^-1   on merkntätapa jolla merkitään logitin käänteisfunktiota. (log-odds todennäköisyydeksi)

logistinen jakauma on S-käppyrä jonka kulmakerroin on isoin lähellä nollaa, sitten tasaantuu. pysyy 0 ja 1 välissä.

dian kohta 8) datagenerointi. the X values are evenly spaced going from -1 to 1.

B0 = logit(0.3).   öööö kuvaaja menee nollan läpi 0.3 kohdalla sanoi hän. niin joo koska tuo on vakiotermi.

MLE. L(B0B1)=(ni!yi!)Pi() ohi.

ell latex symboli kaunokirjoitus L.  log likelihood symboli. etsitään ne vakion ja selittäj(ä/ie)n arvot jotka jotka maksimoivat havaitun datan "uskottavuuden" (likelihood).  tai oikeastaan havaitun datan uskottavuuden logaritmin (log-likelihood)

Newton's method. Solve G(x)=0

hakuammuntoja. kokeillaan ensin nollalla. jos ei tuu arvoks nolla, korjataan jotenkin käyttämällä tangentteja, kolmioita ja kulmakertoimia.

Kulmakerroin = slope coefficient.

curvilinear käyrä. editorialize? mainospuheenomaista puhetta?

AHAA SE KAMALA t yläindeksi tarkoittaa TRANSPOSE-  t() on myös R:ssä transpose komento. diag() ottaa matriisista  diagonaalirivin tai rivit

Newtonin algoritmi, ehkä MLE pitäisi kuulemma kurssin jälkeen osata. 

Newtonin algoritmia käytetään myös Poissonin ja Coxin regressiossa.

jatkuvat selittäjämuuttujat kuulemma usein keskistetään miinustamalla niistä keskiarvo.

vakiotermin P mitataan sitä hypoteesia vastaan että se olisi arvoltaan nolla.

taas tuli esiin että jos otoskoko on riittvän suuri niin pienetkin erot ovat tilastollisesti merkitseviä. mutta se ei välttämättä todellakaan tarkoita, että ne olisivat sisällöllisesti merkittäviä.

jep eli logitissa efektit ovat additiivisia LOGIT-skaalassa.mutta eivät varsinaisessa odds ratiossa.
OR-skaalassa efektit puolestaan ovat kertoimellisia (multiplivative)

logit(p) = b0 + b1x1 + b2x2 + b3xt   <- kolmas on "interaction term"

weight and time are x1 and x2.   if x1 coeffcient changes with time, that's interaction.     the odds ratio of some predictor changes as a function of another prediction. you add an interaction term to the model with x1*x2? maybe?

Caution: all interpretations assume that all relevant variables have been included in the model.

ANOVA-jutut: ohi

kuulemma lääkärit usein kysyvät common OR hantel maenzelin tapaan eivätkä välttämättä tunne logittia niinkään.

jos plotataan todennäköisyyksiä niin yleensä on fiksua laittaa vaihteluväliksi 0,1 kuten läksyssäni älykkäästi teinkin. perus-R:ssä ylim=c(0,1) tämän tekee.

läksy 2 deadline ennen kuin Juha tiistaiaamuna heräjää.

"most model choice literature is useless"

wikipediassa ehkä kuulemma paras selitys fisherin algoritmista.

"entertain a hypothesis" <- slick!

joskus luokkamuuttujien kanssa yksikään sen leveleistä ei ole merkitsevä, mutta kokonaisuutena arvioiden se luokkamuuttuja kuitenkin on merkitsevä.

glm logitin raportoima p-value on Waldin testi. Wald test. Anovan tekemä testi taas on LRT, likelihood ratio test. Tulokset ovat samanmoiset. Tieteellisessä tutkimuksessa on aiheellista mainita kumpaa testiä on käytetty.

Juha sanoo että jos iässä on mahdollisia kynnysarvoja niin saattaa olla informatiivisempaa vertailla vuonna x syntyneiden todennäköisyttä vuonna y syntyneiden todennäköisyyteen sen sijaan, että kerrottaisiin vain OR.

tutkimuksessa kokeillaan kiljoonaa eri mallia. kaikkia ei raportoida tuotoksessa, ainoastaan tärkeimmät. kuitenkin täytyy kertoa että kokeilin tällaista tuollaista ja sellaista mallia, ja niistä parhaaksi osoittautui (se joka raportoidaan).

26.4 eteempäin conditional logit. "conditional logit is for matched data". Hmm...











