---
title: "Applied Logistic Regression -- Assignment 4"
author: "Juho Ruohonen"
date: "DateComesHere, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# 1. Residuals in Logistic Regression
We'll go back to the dataset on Sentiments Toward Racial Integration in Public Housing. That dataset is currently in so-called Bernoulli format, in which one row corresponds to one binary observation. To ease the following computation of residuals, we will convert it into binomial format, which is better for assessing the accuracy of the model predictions for each combination of predictor values.

```{r include=FALSE}
subset1<-data.frame(Proximity=rep(1,times=77),Contact=1,Norms="Favorable",PositiveSentiment=1)
subset2<-data.frame(Proximity=rep(1,times=32),Contact=1,Norms="Favorable",PositiveSentiment=0)
subset3<-data.frame(Proximity=rep(1,times=30),Contact=1,Norms="Unfavorable",PositiveSentiment=1)
subset4<-data.frame(Proximity=rep(1,times=36),Contact=1,Norms="Unfavorable",PositiveSentiment=0)
subset5<-data.frame(Proximity=rep(1,times=14),Contact=0,Norms="Favorable",PositiveSentiment=1)
subset6<-data.frame(Proximity=rep(1,times=19),Contact=0,Norms="Favorable",PositiveSentiment=0)
subset7<-data.frame(Proximity=rep(1,times=15),Contact=0,Norms="Unfavorable",PositiveSentiment=1)
subset8<-data.frame(Proximity=rep(1,times=27),Contact=0,Norms="Unfavorable",PositiveSentiment=0)
subset9<-data.frame(Proximity=rep(0,times=43),Contact=1,Norms="Favorable",PositiveSentiment=1)
subset10<-data.frame(Proximity=rep(0,times=20),Contact=1,Norms="Favorable",PositiveSentiment=0)
subset11<-data.frame(Proximity=rep(0,times=36),Contact=1,Norms="Unfavorable",PositiveSentiment=1)
subset12<-data.frame(Proximity=rep(0,times=37),Contact=1,Norms="Unfavorable",PositiveSentiment=0)
subset13<-data.frame(Proximity=rep(0,times=27),Contact=0,Norms="Favorable",PositiveSentiment=1)
subset14<-data.frame(Proximity=rep(0,times=36),Contact=0,Norms="Favorable",PositiveSentiment=0)
subset15<-data.frame(Proximity=rep(0,times=41),Contact=0,Norms="Unfavorable",PositiveSentiment=1)
subset16<-data.frame(Proximity=rep(0,times=118),Contact=0,Norms="Unfavorable",PositiveSentiment=0)
contact<-rbind(subset1,subset2,subset3,subset4,subset5,subset6,subset7,subset8,subset9,subset10,
  subset11,subset12,subset13,subset14,subset15,subset16)
model<-glm(PositiveSentiment ~ Contact + Norms, family=binomial(link=logit), data = contact)
```
```{r}
w<-aggregate(PositiveSentiment ~ Contact + Norms, FUN = sum, data=contact)
n<-aggregate(PositiveSentiment ~ Contact + Norms, FUN = length, data=contact)
(Contact<-data.frame(Contact=w$Contact, Norms=w$Norms, Y=w$PositiveSentiment, 
  Obs.=n[,3], p=w$PositiveSentiment/n[,3]))
summary(Model<-glm(Y/Obs. ~ Contact + Norms, weights = Obs., 
  family=binomial(link=logit), data=Contact))
```  
In logistic regression, the residual of a single observation is of limited interest due to its dichotomous nature -- with the response limited to 0 or 1, its residual is also limited to theoretical maximum of 1. Therefore, rather than examining residuals of individual observations, it is more illuminating to group the data by each distinct _covariate pattern_ -- also known as explanatory variable pattern or EVP -- i.e., each distinct combination of predictor values observed in the data. Each group sharing an EVP also necessarily shares the same predicted probability. Multiplying each group's $n$ by the predicted probability yields the expected number of success outcomes for that group, which can then be compared to the observed success count. Assuming $n$ is sufficiently large for a given covariate pattern, the difference between the observed and expected success counts is asymptotically standard normal.

Grouping by EVP requires that the explanatory variables be categorical. The presence of a truly continuous covariate in the model has the consequence that the number of EVPs approaches or equals the total number of observations in the dataset. In such scenarios, we need the Hosmer-Lemeshow procedure, which groups the data by deciles of predicted probability instead of covariate patterns. Fortunately, both predictors in our racial integration model are dichotomous. We will now calculate both the Pearson residuals and deviance residuals for each covariate pattern:

```{r}
Contact$phat<-fitted.values(Model)
Contact$yhat<-with(Contact,Obs.*phat)
Contact$PearsonRes<-with(Contact,(Y-yhat)/sqrt(yhat*(1-phat)))
Contact$DevianceRes<-with(Contact, 
  sign(Y-yhat)*sqrt(2)*sqrt(Y*log(Y/yhat)+(Obs.-Y)*log((Obs.-Y)/(Obs.-yhat))))
Contact[,c(1:2,5:6,3,7:9)]
```
The group-specific residuals suggest a good fit. None of them is anywhere near 1.96 standard deviations in absolute value. We'll also calculate a summary statistic of the fit by adding up the squared Pearson residuals. This statistic follows a chi-squared distribution, with degrees of freedom equal to the number of covariate patterns (groups) minus the number of parameters (intercept plus predictors):

```{r}
(OverallPearson <- sum(Contact$PearsonRes^2))
1-pchisq(OverallPearson, df = 1)
```  
The residual degrees of freedom equal the number of binomial observations (4) minus the number of parameters in the model (3) = 1. The p-value is .43, indicating a statistically non-significant lack of fit. We can thereby conclude that the model fits quite well.

# 2. Effects of Variable Centering: Simulation
```{r}
n <- 50
G <- c(rep(1,20),rep(0,30))
x <- vector(); for(i in 1:n) {xi <- i/n; x <- c(x,xi)}; rm(xi)
X <- cbind(rep(1,n),G,x)
B <- c(-0.9, 0.3, 1)
logodds <- X[,1]*B[1] + X[,2]*B[2] + X[,3]*B[3]
p <- exp(logodds)/(1+exp(logodds))
N <- 300

# x NOT centered:
MLEs <- data.frame()
for (i in 1:N){
  U <- runif(n)
  y <- as.numeric(p > U)
  model <- glm(y ~ G+x, family=binomial(link=logit))
  MLEs <- rbind(MLEs, coef(model))
};rm(model,y,U); names(MLEs)<-c("B0","B1","B2")
#Look at the MLEs:
sapply(MLEs, mean);cat("\n B2B0 correlation:\n");with(MLEs,cor(B2,B0))

#x CENTERED:
x2 <- x-mean(x)
MLEs.2 <- data.frame()
for (i in 1:N){
  U <- runif(n)
  y <- as.numeric(p > U)
  model <- glm(y ~ G+x2, family=binomial(link=logit))
  MLEs.2 <- rbind(MLEs.2, coef(model))
};rm(model,y,U); names(MLEs.2)<-c("B0","B1","B2")
#Look at the MLEs:
sapply(MLEs.2, mean);cat("\n B2B0 correlation:\n");with(MLEs.2,cor(B2,B0))

library(ggplot2)
(scatter1<-ggplot(data=MLEs, aes(x=B0, y=B2)) +
  geom_point(aes(x=B0,y=B2)) +
  ggtitle("X not centered"))
(scatter2<-ggplot(data=MLEs.2, aes(x=B0, y=B2)) +
  geom_point(aes(x=B0,y=B2)) +
  ggtitle("X centered around its mean. Note the change in scale!"))
```

The constant term, or intercept, is the estimated logit of the outcome when all continuous covariates equal 0 and all categorical covariates are at their reference level. This means that the coding of continuous covariates ought to be given careful thought -- else the MLE for the intercept becomes uninteresting. In general, centering continuous covariates around their means and contrasting qualitative covariates with their most common category simplifies the interpretation of any regression model -- in particular, it makes the constant term immediately informative. This is well illustrated by continuous covariates such as a subject's height and weight, where zero values are impossible in real data. Without centering, the intercept will be the logit-scale probability of the outcome for an individual who weighs 0 pounds and stands 0 feet tall, which is much less useful than an intercept representing the logit-scale probability for a person of average weight and height.

In our simulation data above, the true mean probability of the outcome is .43. The uncentered continuous covariate $x$ takes on positive values from 0 to 1. True $B2$ is 1, while "true" $B0$ (intercept) is -0.9. If we center $x$ around a smaller value after the outcomes are generated, its MLE remains the same because it is not based on the $x$ values themselves but on the relationship between the observed variation in $x$ and the observed variation in $y$. $B0$, by contrast, represents not the relationship between some variable and the outcome but the estimated logit-scale probability of the outcome before the covariates have had an effect -- in other words, when they equal zero. Therefore, when the values of $x$ are reduced, i.e., brought closer to zero by centering it while the data is kept fixed, $B0$ must necessarily increase, because the effect of $x$ at "zero" now represents the effect of $x$ at its mean.

All of the above entails that it is possible to manipulate the intercept of a model in almost any way we want by adjusting the origins and/or scales of the continuous covariates. Such manipulation is sometimes advisable if it can make the interpretation of the model coefficients simpler and more intuitive.
  
# 3. Conditional Logistic Regression for Matched-Pairs Case Control Data

We'll now investigate what factors might be associated with low birth weight in newborns. The data comes in matched-pairs case-control format, so we'll use conditional logistic regression to remove the unmeasured, pair-specific effects from the equation. The measured covariates available are:

1. Race (nominal: 1=white, 2=black, 3=other)
2. Smoking during pregnancy (dichotomous)
3. PTD: history of premature labor (dichotomous)
4. HT: History of hypertension (dichotomous)
5. UI: Intrauterine Irritability (dichotomous)

I began the analysis by entering the aforementioned 5 variables plus every conceivable two-way interaction term into the model. It was messy and therefore isn't shown here. Many of the interactions could not be analyzed because the data was too sparse, or there were singularities. Out of the interactions that could be analyzed, however, none was statistically significant. We can thus proceed to fitting a model with main effects only:

```{r}
library(survival)
lowbw <- read.table(file="lowbwtm11CSV.csv",sep=";",header=T)
names(lowbw)
names(lowbw)[1]<-"PAIR"
lowbw$RACE <- as.factor(lowbw$RACE)
levels(lowbw$RACE) <- c("WHITE","BLACK","OTHER")
summary(bw1 <- clogit(LOW ~ RACE + SMOKE + PTD + HT + UI + strata(PAIR), data = lowbw))

```
Race is about to be dropped from the model. We'll verify this through a comparison of nested models:

```{r}
bw2 <- clogit(LOW ~ SMOKE + PTD + HT + UI + strata(PAIR), data = lowbw)
anova(bw1,bw2,test = "Chisq")
```  

Dropping RACE did not significantly worsen the fit, and it made the model more parsimonious:
```{r}
summary(bw2)
```
All the remaining variables are significant. Intrauterine irritability has a p-value on the borderline of significance, but we'll keep it in the model. Newborn babies' health is at stake here, so it's prudent to be cautious and attentive of any suspicious factors, even if they fall 2.7 per mille short of the conventional significance threshold. The model output shows the logit-scale MLEs converted into odds ratios as well as the 95% confidence intervals of these odds ratios: smoking during pregnancy increases the odds of the baby having a low birth weight by a factor of 1.4 to 11. For those having a history of premature labor, the odds of delivering a baby with a low birth weight are from 1.3 to 20 times as high as the odds for those without such a history. Hypertension increases the odds by a factor ranging from 1.05 to 23. Intrauterine irritability multiplies the odds by factor of 1 to 15.

# 4. Predicting Membership in the Hilmo Drug User Database 
We'll now use logistic regression to model the probability of double registration for criminal drug users. Unfortunately the data file is not in a format immediately usable by R, so we have to edit it a little before importing: 
```{r}
orig.file<-scan(what="char",file="drug-users.txt",sep="\n")
head(orig.file,10)
library(stringr)
drug_orig<-str_replace_all(orig.file[7:length(orig.file)],"^ +","")
drug_orig<-str_replace_all(drug_orig," +","\t")
drug_orig<-str_replace_all(drug_orig,"\t(?=$)",""); cat(drug_orig,file="drug_orig.txt",sep="\n")
drug_orig<-read.table(file="drug_orig.txt",sep="\t",header=T)
```
We also have to convert the relationship status variable from numeric to nominal:

```{r}
drug_orig$sta<-as.factor(drug_orig$sta); levels(drug_orig$sta)
(levels(drug_orig$sta)<-c("HasPartner","Single","Widowed","Divorced",NA))
drug_orig[which(is.na(drug_orig$sta)),]
```
Unfortunately, this lone NA value in the _sta_ varuabke __will cause problems__ with our probability calculations later. A NA value will prevent the automated calculation of a fitted probability for that observation, which will consequently prevent the calculation of means and other statistical parameters for the fitted probabilities. We will therefore impute a likely value for the missing field. And since the _sta_ variable is categorical, what better way to impute it than logistic regression? We'll just need to use the polytomous variety:

```{r}
library(nnet)
drug <- drug_orig
drug$sta[98] <- predict(
  multinom(sta ~ riki + hilmo + age + male, data=drug), newdata=drug[98,], type="class")
drug[98,]
```
Much better. Now we can proceed.

There are two databases that keep track of drug users in Finland -- the Hospital Discharge Register _hilmo_ and the Criminal Report Register _riki_. Our aggregate dataset _drug_ lists everyone who was registered as a drug user in one or both of these databases around the year 2000. The ultimate goal of these exercises is to estimate the total number of drug users in the Uusimaa province of Southern Finland at the turn of the millennium. First we will model the probability that subjects registered in _riki_ are also found in hilmo. Thecovariates at our disposal are age, sex, and relationship status. We'll start by analyzing the main effects plus all potential two-way interactions. Also, having learned from exercise 2, we'll center the age variable around its mean:

```{r}
d0<-drug[drug$riki==1,]
d0$ageCentered<-d0$age-mean(d0$age)
summary(drugmodel0<-glm(hilmo ~ ageCentered*male + male*sta + ageCentered*sta, 
  family=binomial(link=logit), data=d0))
```
```{r include=FALSE}
summary(drugmodel1b<-glm(hilmo ~ age + male + sta, family=binomial(link=logit), data=d0))
```
None of the interactions is significant, so we'll drop them. Next, we'll analyze main effects only:  


```{r}
summary(drugmodel1<-glm(hilmo ~ ageCentered + male + sta, family=binomial(link=logit), data=d0))
```
Thanks to our centering of age, the intercept is immediately relevant. It tells us that, according to this model, a drug user who is aged 28, female, and in a relationship, has a probability of $$e^-2.58388/(1+e^-2.58388) = .07$$ of inclusion in _hilmo_. Age is negatively associated with inclusion in the database, while being Widowed has a very strong positive association. Maleness is negatively associated -- a phenomenon which is intuitively believable since common sense suggests that men are less likely than women to seek medical help in distress. The effect falls just short of statistical significance, however.

Within the categorical variable describing relationship status, only the Widowed category has a significant effect. It is therefore worthwhile experimenting with a dummy variable that indicates simply whether the person is Widowed (1) or not (0). This effectively collapses the three remaining levels together into one large reference category representing the vast majority of the subjects in the dataset:

```{r}
d0$Widowed<-as.numeric(d0$sta=="Widowed")
summary(drugmodel2<-glm(hilmo~ageCentered+male+Widowed,family=binomial(link=logit),data=d0))
anova(drugmodel1,drugmodel2,test="LRT")
```
This is a clear improvement. Residual deviance increased only negligibly (p = .67), while df improved by 2 points and AIC by 5 points. We'll keep this change. Next, let's try breaking age into cohorts in order to examine the exact nature of its effect. We'll contrast the other age brackets with the one containing the mean.

```{r}
summary(d0$age)
hist(d0$age)
d0$agegroup<-cut(d0$age,breaks=c(min(d0$age),19,24,29,34,39,44,49,max(d0$age)),include.lowest = TRUE)
addmargins(table(d0$agegroup)); nrow(d0)
d0$agegroup<-relevel(d0$agegroup,ref="(24,29]")
summary(drugmodel3<-glm(hilmo~agegroup+male+Widowed,family=binomial(link=logit),data=d0))
```
The effect of age not linear. Instead, it seems to have a similar effect as it does on athletic performance, which is generally high in youth, peaks in the late 20s and then starts to deteriorate as a function of time. The reference category (25-to-29-year-olds) has by far the highest risk of inclusion.  

One unexpected consequence of dividing age into cohorts is that maleness becomes statisically significant, which it wasn't in the model where age was continuous. How can this be explained? One possibility is that one or more of the cohorts may, purely by chance, have a high proportion of males avoiding hospitalization on the top end of the age bracket. With age as categorical, the model would attribute such within-bracket associations between age and the outcome solely to maleness rather than dividing it between age and maleness.  
  
Which is the better model between the one with continuous age and the one where it's bracketed? We cannot compare them directly using a LRT because the models are not nested -- one treats age as continuous, the other as nominal, so this is a matter of different variables rather than extra variables.

Judging by the smaller AIC, we should perhaps prefer the simpler model with continuous age to the one with age brackets. Though the effect of age is not exactly linear, the overall trend is still that old people are less likely to be registered than young people. In fact, a binary age division between the old and the young might further improve the model. The output of the bracketed-age model already gives us clues as to what the best threshold value might be. We'll try to find one now.
  
After experimenting with different age cutoffs (not shown), I learned that a binary age distinction between those under 33 and the rest results in a better fit than having age as continuous, and the model is equally parsimonious.

```{r}
d0$AgeUnder33<-as.numeric(d0$age<33)
summary(drugmodel4<-glm(hilmo~AgeUnder33+Widowed+male,family=binomial(link=logit),data=d0))
anova(drugmodel2, drugmodel4)
```  
The age-bracketed model above has lower residual deviance, but its higher number of parameters results in diminished parsimony and a higher AIC (807.33 as opposed to the current model's 800.83). Therefore, drugmodel4 is our choice. It's got three binary predictors, each of which has high predictive power and is simple to interpret. We'll finish by predicting the probabilities of belonging to _hilmo_ for every subject in the entire drug dataset, and viewing 10 of them at random:

```{r}
drug$Widowed<-as.numeric(drug$sta=="Widowed")
drug$AgeUnder33<-as.numeric(drug$age<33)
drug$FittedHilmoProbs <- predict(drugmodel4,newdata=drug,type="response")
sample(drug$FittedHilmoProbs, size=10)
```  

# 5. Predicting Membership in Criminal Report Rekister Riki
Now we'll perform a similar analysis in the other direction, trying to predict whether those registered as drug users in _hilmo_ have been caught committing crimes and listed in _riki_ as drug users. We'll begin with a model containing all the main effects and potential two-variable interactions. We will also center age around its mean again:  

```{r}
d1<-drug[drug$hilmo==1,]; row.names(d1)<-1:nrow(d1)
d1$ageCentered<-d1$age-mean(d1$age)
summary(DrugModel0<-glm(riki ~ ageCentered*male + male*sta +ageCentered*sta, family=binomial(link=logit), data=d1))
```  

None of the interaction terms is significant, and the whole model is quite confusing to interpret. We'll drop the interactions:

```{r}
summary(DrugModel1<-glm(riki ~ ageCentered + male + sta, family=binomial(link=logit), data=d1))
```
Here, age has an even stronger (disfavoring) effect than in the previous dataset. This makes intuitive sense -- the old are less hotheaded than the young and therefore less prone to rash acts of violence and crime. Much like the risk of inclusion in _hilmo_, being Widowed also increases the risk of inclusion in _riki_. Maleness increases the risk of inclusion, but at p = .12 the effect falls somewhat short of statistical significance. Let's study the effect of age more closely by dividing the variable into cohorts:

```{r}
summary(d1$age); hist(d1$age)
d1$agegroup<-cut(d1$age,breaks=c(min(d1$age),19,24,29,34,39,44,49,max(d1$age)),include.lowest = TRUE)
addmargins(table(d1$agegroup)); nrow(d1)
d1$agegroup<-relevel(d1$agegroup,ref="(24,29]") #Make 25-30 the reference level
summary(DrugModel2<-glm(riki ~ agegroup + male + sta, family=binomial(link=logit), data=d1))
```
The effect of age seems similarly shaped as in the previous dataset -- its favoring effect peaks in the late twenties, then reverses. I'll now see if I can find a threshold value at which age could be conveniently dichotomized to improve the model (experimentation not shown).  

It appears that 33 is the best threshold for a binary age classification is this dataset too:

```{r}
d1$AgeUnder33<-as.numeric(d1$age<33)
summary(DrugModel3<-glm(riki~AgeUnder33+male+sta,family=binomial(link=logit),data=d1))
anova(DrugModel1,DrugModel3)
```  
This model fits the data better, on the same degrees of freedom, as the one where age was continuous. It seems safe to prefer the binary classification.

A further improvement can be accomplished by removing the non-significant distinction between single and divorced people within the _sta_ variable. We will collapse these two categories together into a new reference category that will be contrasted with the more statistically significant classes. Being Widowed is clearly significant, but having a partner might be significant too -- we have no direct measure of its effect because it is the variable's current baseline, and it is being contrasted with three different categories. By changing the baseline to Single/Divorced, we will get an overt estimate of the effect of having a partner. The merging the two non-significant cateogries will gain us a degree of freedom at little cost in residual deviance. We will call our new, trimmed version of the variable _sta.3way_:

```{r}
levels(d1$sta)
d1$sta.3way <- d1$sta
levels(d1$sta.3way) <- c("HasPartner","Single/Divorced", "Widowed", "Single/Divorced")
d1$sta.3way <- relevel(d1$sta.3way, "Single/Divorced")
summary(DrugModel4<-glm(riki~AgeUnder33+male+sta.3way,family=binomial(link=logit),data=d1))
anova(DrugModel3,DrugModel4,test="LRT")
```
The chi-square statistic for the increase in deviance is only .77 at 1 degree of freedom, which supports our decision to trim the variable.

We now face a decision regarding the gender variable. It is not having the same effect as in the _riki_ dataset. Let's try dropping it:  

```{r}
summary(DrugModel5<-glm(riki~AgeUnder33+sta.3way,family=binomial(link=logit),data=d1))
anova(DrugModel4,DrugModel5,test = "LRT")
```  
At p = 0.24, there is relatively robust statistical evidence for removing gender from the model. We will drop the variable. However, since gender is always of scientific interest, we will state for the record that its effect on inclusion in _riki_ generally ranged between 1 and 1.6 on the z-scale, varying according to what other predictors were in the model.

The choices get harder from this point on. We will make use of two more statistics in our endeavor to select the best model. In addition to the familiar LRT, ANOVA and AIC, we will be measuring each model candidate's testing error in leave-one-out crossvalidation. Secondly, we will calculate BIC for each model. AIC and BIC are both designed to provide a measure of the model's fit while taking its complexity into account. They accomplish this by adding a penalty to the deviance residual for each additional parameter, and their difference lies in the magnitude of that penalty. No consensus exists on which criterion is better, but AIC is considered relatively lenient towards added complexity, while BIC penalizes it more severely. 

The two relationship statuses contrasted with the new baseline have opposite effects of almost identical magnitude. Both also fall somewhat short of the statistical significance threshold. Let's see what happens if we remove the ostensibly least significant remaining variable, i.e., the indicator for having a romantic partner.

```{r}
summary(DrugModel6<-glm(riki~AgeUnder33+Widowed,family=binomial(link=logit),data=d1))
anova(DrugModel5,DrugModel6,test = "LRT")
if(exists("survival",mode="function")){detach("package:survival",unload=TRUE)}
library(boot) 
ErrorRate<-function(Y,prob){mean(abs(Y-prob)>0.5)} #Define how Error Rate is calculated
ModelCandidates<-data.frame(TestingErrorCV=cv.glm(data=d1,glmfit=DrugModel5,
  cost=ErrorRate)$delta[1],AIC=DrugModel5$aic,BIC=BIC(DrugModel5),DevianceRes=DrugModel5$deviance,
  row.names="AgeUnder33+sta.3way") 
ModelCandidates<-rbind(ModelCandidates,
  "AgeUnder33+Widowed"=c(TestingErrorCV=cv.glm(data=d1,glmfit=DrugModel6,
  cost=ErrorRate)$delta[1],AIC=DrugModel6$aic,BIC=BIC(DrugModel6),DevianceRes=DrugModel6$deviance))
ModelCandidates
```
P-value for removing the indicator is .11. Though not statistically significant, I find this unsettlingly low. AIC also deteriorates. BIC improves, but deviance jumps by 2.5 points. Testing error rates are identical. This evidence is very inconclusive. Before deciding, let's check what happens if we remove the widowhood indicator instead, and keep the dummy for having a partner. 

```{r}
d1$HasPartner<-as.numeric(d1$sta.3way=="HasPartner")
summary(DrugModel6b<-glm(riki~AgeUnder33+HasPartner,family=binomial(link=logit),data=d1))
anova(DrugModel5,DrugModel6b,test="LRT")
ModelCandidates<-rbind(ModelCandidates,
  "AgeUnder33+HasPartner"=c(TestingErrorCV=cv.glm(data=d1,glmfit=DrugModel6b,
  cost=ErrorRate)$delta[1],AIC=DrugModel6b$aic,BIC=BIC(DrugModel6b),DevianceRes=DrugModel6b$deviance))
```

Paradoxically, removing the widowhood indicator has less of an effect on deviance than removing the indicator for having a romantic partner, even though the former variable was estimated to be a more significant predictor. How can this be? The answer lies in different vastly different $n$'s.

```{r}
table(d1$sta.3way)
```  
Widowhood is the better predictor in the few cases where it applies, but it is applicable to less than 1% of the subjects in the dataset. HasPartner is applicable to over 10% of the data. Thus, removing HasPartner worsens the fit considerably more than does removing Widowed, even though the former's predictive power on a single observation is slightly lower. Put another way, the widowhood dummy looks more impressive in the model output but is overall less useful than HasPartner. CV Testing Error remains identical between models 5 and 6b. AIC and BIC, as well as LRT, seem to support the removal of the widowhood dummy, so out it goes. Two predictors remain. Can we remove one?

```{r}
DrugModel7<-glm(riki~AgeUnder33,family=binomial(link=logit),data=d1)
anova(DrugModel6b,DrugModel7,test="LRT")
(ModelCandidates<-rbind(ModelCandidates,
  "AgeUnder33"=c(TestingErrorCV=cv.glm(data=d1,glmfit=DrugModel7,
  cost=ErrorRate)$delta[1],AIC=DrugModel7$aic,BIC=BIC(DrugModel7),DevianceRes=DrugModel7$deviance)))
```  

No, I don't think this removal is a good idea. The p-value for dropping HasPartner is below .10, and the deviance increase is unsavory. We have a pretty good model now. It is parsimonious with only two predictors, both of which make intuitive sense are simple to interpret. However, we perhaps do still a little better in terms of predictive power. Let's look more closely at the effect of relationship status:
```{r}
table(d1$sta.3way,d1$riki)
```
Widowed people seem at an elevated risk of inclusion in _riki_. We knew this. Now let's condition the effect on sex:
```{r}
cat("men\n");with(d1[d1$male==1,],table(sta.3way,riki));cat("\n\n")
cat("women\n");with(d1[d1$male==0,],table(sta.3way,riki))
```
The odds ratio of being in _riki_ between widowed men and widowed women is infinite. For the bigger picture, let's view the same conditional crosstables from the _riki_ dataset from the previous exercise:

```{r}
cat("men\n");with(d0[d0$male==1,],table(sta,hilmo));cat("\n\n")
cat("women\n");with(d0[d0$male==0,],table(sta,hilmo))
```
Again the odds ratio between women and men is infinite. Based on this (very limited) data, widowhood seems much more dangerous to women than to men. The implication for our model selection exercise is that we should consider making a dummy variable for being a widow in the word's exact sense, i.e., a __woman__ who has lost her partner to death and remains alone.

```{r}
d1$fem.widow<-as.numeric(d1$male==0 & d1$Widowed)
summary(DrugModel8<-glm(riki~AgeUnder33+HasPartner+fem.widow,family=binomial,data=d1))
(ModelCandidates<-rbind(ModelCandidates,
  "AgeUnder33+HasPartner+fem.widow"=c(TestingErrorCV=cv.glm(data=d1,glmfit=DrugModel8,
  cost=ErrorRate)$delta[1],AIC=DrugModel8$aic,BIC=BIC(DrugModel8),DevianceRes=DrugModel8$deviance)))
anova(DrugModel6b,DrugModel8,test="LRT")
```
The improvement in fit that is achieved by adding the dummy for being a widow has a p-value of .10, so there's no clear-cut answer to whether its inclusion is justified. It is risky to include covariates whose predictive power is based on such tiny samples -- the reported effect could very well be due to mere chance. To illustrate, let's compare these three predictors by the extent to which they are influenced by single observations:

```{r}
leverage <- dfbetas(DrugModel8); leverage <- as.data.frame(leverage)
(maxlev<-sapply(abs(leverage), max))
```
The _dfbeta_ estimates how much the MLE of the covariate would change if the observation was deleted. We can see that the maximum leverage of an individual observation on the widow dummy is about 3 to 4 times as high as on the other two covariates. We see this difference leverage difference at work when we delete a single observation exerting maximum influence for each predictor and compare the changes in the MLEs:

```{r}
leverage[which(abs(leverage$fem.widow)==maxlev["fem.widow"]),]
leverage[which(abs(leverage$HasPartner)==maxlev["HasPartner"]),]
summary(glm(riki~AgeUnder33+HasPartner+fem.widow,family=binomial,data=d1[c(-128,-393),]))
```
The MLE for AgeUnder33 stays virtually unchanged. HasPartner becomes more significant as its p-value decreases from .14 to .8 -- this is because the most influential observation is one that deviates from the general trend, so getting rid of it makes the trend more clear. The effect of the widow dummy, on the other hand, is based on a mere 2 success outcomes, thus it vanishes completely when we remove one of them.

At the same time, the effect of being a widowed female has the same direction in both datasets -- a strong positive association. Our choice is whether to ignore this effect due to the small sample or to assume that the association seen in this meager sample is an indicator of a wider phenomenon of prematurely widowed women having an elevated risk of antisocial and self-destructive behavior. 

I choose to "believe my data" here. Losing your husband/boyfriend to death at a young age is undoubtedly a traumatic experience, so it stands to reason that women having experienced it are more susceptible to problem behavior. There seems no particular reason to assume that the effect if due to chance alone. Therefore, the final model chosen to predict _riki_ membership is DrugModel8, containing AgeUnder33 and the dummies HasPartner and fem.widow. We'll now create these dummy variables for the combined _drug_ dataset, and then use the model to predict the probability of inclusion in _riki_ for every subject.



```{r}
drug$HasPartner<-as.numeric(drug$sta=="HasPartner")
drug$fem.widow<-as.numeric(drug$male==0 & drug$sta=="Widowed")
drug$FittedRikiProbs<-predict(DrugModel8, newdata=drug, type="response")
```
```{r eval=FALSE, include=FALSE}
d1$fem.widow<-as.numeric(d1$male==0 & d1$sta=="Widowed")
summary(DrugModel8<-glm(riki~AgeUnder33+HasPartner+fem.widow,family=binomial(link=logit),data=d1))
summary(DrugModel9<-glm(riki~AgeUnder33+fem.widow,family=binomial(link=logit),data=d1))
anova(DrugModel8,DrugModel6b,test="LRT")
anova(DrugModel9,DrugModel7,test="LRT")
(ModelCandidates<-rbind(ModelCandidates,
  "AgeUnder33+HasPartner+fem.widow"=c(TestingErrorCV=cv.glm(data=d1,glmfit=DrugModel8,
  cost=ErrorRate)$delta[1],AIC=DrugModel8$aic,BIC=BIC(DrugModel8),DevianceRes=DrugModel8$deviance),
  "AgeUnder33+fem.widow"=c(TestingErrorCV=cv.glm(data=d1,glmfit=DrugModel9,
  cost=ErrorRate)$delta[1],AIC=DrugModel9$aic,BIC=BIC(DrugModel9),DevianceRes=DrugModel9$deviance)))
```
# 6. The Horvitz-Thompson Estimator of Population Total
If we take a random sample from a population of unknown size, mark each subject in the sample, release them back into the population, and then collect a new random sample of the same population, the degree of overlap between the two random samples is going to be approximately inversely proportional to the total population size. This is the capture-recapture method, which is used to estimate population sizes in fields such as biology. In our example, we are estimating the total population of drug users in Uusimaa, and our two random samples are the _hilmo_ and _riki_ registries, both of which keep independent track of drug users in the area. As per the instructions, we'll rename the _hilmo_ and _riki_ inclusion probabilities calculated for each subject in the _drug_ dataset as $p1$ and $p2$, respectively:

```{r}
names(drug)[which(names(drug)=="FittedHilmoProbs")]<-"p1"
names(drug)[which(names(drug)=="FittedRikiProbs")]<-"p2"
#drug<-drug[,c(1,2,4,7,6,9,10,8,11)]
```
For each of the 2593 subjects, the probability of being registered in either _hilmo_ or _riki_ is:

```{r}
drug$theta <- with(drug, p1+p2 - p2*p2)
```
Here's a summary of _theta_:
```{r}
summary(drug$theta)
```  
Our two models rely on a combined total of 5 explanatory variables, all of which are dichotomous. In the _drug_ dataset, 12 different combinations of these variables occur. The following table lists the estimated $p1$, $p2$, and $theta$ for each combination. I'll leave the fem.widow dummy out of this summary table to save space, because it is already implicitly included as the 0,1 combination of male and widowed:
```{r}
EVPs.Bernoulli<-split(drug, list(drug$AgeUnder33,drug$Widowed,drug$male,drug$HasPartner),drop=TRUE)
EVPs <- data.frame(); n<-vector()
for(i in 1:length(EVPs.Bernoulli)){
    EVPs <- rbind(EVPs,EVPs.Bernoulli[[i]][1,]); n<-c(n,nrow(EVPs.Bernoulli[[i]]))}
EVPs$n<-n; row.names(EVPs)<-1:nrow(EVPs)
EVPs<-EVPs[,c(7,4,6,9,8,11:13)]
round(EVPs,digits=6)
```  
Let __u1 = age under 33, m1 = male, w1 = widowed, and h1 = has a partner__. The following plot illustrates the variation in $theta$ across covariate patterns:

```{r}
EVPs<-cbind(pattern=c("u0m0w0h0","u1m0w0h0","u0m0w1h0","u1m0w1h0","u0m1w0h0",
  "u1m1w0h0","u0m1w1h0","u1m1w1h0","u0m0w0h1","u1m0w0h1","u0m1w0h1","u1m1w0h1"),EVPs)
ggplot(EVPs, aes(x=pattern)) + geom_col(aes(y=theta)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12)) +
  geom_text(aes(y=theta,label=n), vjust=1.5, colour="white") + 
  ggtitle("Probability of inclusion in at least one drug user database,\n by covariate pattern",
  subtitle="N = 2593")
```
The right side of the plot represents those under 33. The left side are the older people. In both age groups, it is the widowed women followed by the widowed men who have the highest estimated probability of inclusion. We can also see how low $n$ is in each of these four groups. 

Finally, we'll calculate the Horvitz-Thompson estimate of the population total of drug users in Uusimaa around 2000. It is the sum over the inverse inclusion probabilities (thetas) of each subject in the full dataset:

```{r}
(Horvitz.Thompson <- sum(1/drug$theta))
```
Based on the probability estimates yielded by our models, there were approximately 19,000 drug users in Uusimaa at the turn of the century.

***